# -*- coding: utf-8 -*-
"""Image Dehaze.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CxFXBb7NOMcKqz8lYkib7f3u4N9KNO_j
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import glob
import random
from PIL import Image
import time
import datetime, zipfile

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.losses import mean_squared_error
from tensorflow.keras.optimizers import Adam

from google.colab import drive
drive.mount('/content/drive')

import os
import tensorflow as tf

# Path to the folder where your images are stored
data_dir = '/content/drive/MyDrive/data'

# Function to get a list of all image file paths in the data directory
def get_image_paths(data_dir):
    image_paths = []
    for root, dirs, files in os.walk(data_dir):
        for file in files:
            if file.endswith(('.png', '.jpg', '.jpeg')):
                image_paths.append(os.path.join(root, file))
    return image_paths

# Fetch image paths
image_paths = get_image_paths(data_dir)
print(f"Total images found: {len(image_paths)}")

def load_image(img_path):
    img = tf.io.read_file(img_path)  # Returns string type tensor
    img = tf.io.decode_jpeg(img, channels=3)  # Decode the image
    img = tf.image.resize(img, size=(384, 384), antialias=True)  # Resize the image
    img = img / 255.0  # Normalize the image
    return img

# Create a TensorFlow dataset from the image paths
image_paths = tf.convert_to_tensor(image_paths, dtype=tf.string)
image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)

# Map the load_image function to each element in the dataset
image_dataset = image_dataset.map(lambda x: load_image(x), num_parallel_calls=tf.data.AUTOTUNE)

# Batch the dataset and prefetch for performance
batch_size = 32
image_dataset = image_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)

# Verify the dataset loading by displaying some images
import matplotlib.pyplot as plt

for batch in image_dataset.take(1):
    plt.figure(figsize=(10, 10))
    for i in range(min(batch_size, len(batch))):
        ax = plt.subplot(6, 6, i + 1)
        plt.imshow(batch[i].numpy())
        plt.axis("off")
    plt.show()

# function to get the path of individual image.

def data_path(orig_img_path, hazy_img_path):

    train_img = []
    val_img = []

    orig_img = glob.glob(orig_img_path + '/*.jpg')
    n = len(orig_img)
    random.shuffle(orig_img)
    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test
    val_keys = orig_img[int(0.9*n):]

    split_dict = {}
    for key in train_keys:
        split_dict[key] = 'train'
    for key in val_keys:
        split_dict[key] = 'val'

    hazy_img = glob.glob(hazy_img_path + '/*.jpg')
    for img in hazy_img:
        img_name = img.split('/')[-1]
        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'
        if (split_dict[orig_path] == 'train'):
            train_img.append([img, orig_path])  # img -> hazy image path
        else:
            val_img.append([img, orig_path])

    return train_img, val_img

def dataloader(train_data, val_data, batch_size):

    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))
    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))
    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100, reshuffle_each_iteration=True).batch(batch_size)

    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))
    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))
    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100, reshuffle_each_iteration=True).batch(batch_size)

    return train, val

def display_img(model, hazy_img, orig_img):

    dehazed_img = model(hazy_img, training = True)
    plt.figure(figsize = (15,12))

    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]
    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']

    for i in range(3):
        plt.subplot(1, 3, i+1)
        plt.title(title[i])
        plt.imshow(display_list[i])
        plt.axis('off')

    plt.show()

def gman_net():

    inputs = tf.keras.Input(shape = [384, 384, 3])     # height, width of input image changed because of error in output

                                    ######################## GMAN Network ###########################

    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)
    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)


                                    #### Encoding Layers #####
    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv)
    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)

                                    #### Residual Layers #####
    conv1_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)
    conv1_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_1)
    conv1_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_2)
    conc1 = tf.add(conv1_3, conv1_1)
    conv1 = tf.keras.activations.relu(conc1)

    conv2_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1)
    conv2_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_1)
    conv2_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_2)
    conc2 = tf.add(conv2_3, conv2_1)
    conv2 = tf.keras.activations.relu(conc2)

    conv3_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2)
    conv3_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_1)
    conv3_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_2)
    conv3_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_3)
    conv3_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_4)
    conc3 = tf.add(conv3_5, conv3_1)
    conv3 = tf.keras.activations.relu(conc3)

    conv4_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3)
    conv4_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_1)
    conv4_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_2)
    conv4_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_3)
    conv4_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_4)
    conc4 = tf.add(conv4_5, conv4_1)
    conv4 = tf.keras.activations.relu(conc4)

                                            ##### Decoding Layers #####
    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                             kernel_regularizer = regularizer)(conv4)
    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                             kernel_regularizer = regularizer)(deconv)

    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                  bias_initializer = b_init, kernel_regularizer = regularizer)(deconv)
    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)
    conc = tf.add(conv, inputs)
    gman_output = tf.keras.activations.relu(conc)

                               ######################## Parallel Network ###########################

    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(inputs)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                           activation = 'relu', kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                 kernel_regularizer = regularizer)(deconv)
    conc = tf.add(conv, inputs)
    pn_output = tf.keras.activations.relu(conc)

    output = tf.add(gman_output, pn_output)

    return Model(inputs = inputs, outputs = output)

epochs = 15
batch_size = 16
k_init = tf.keras.initializers.RandomNormal(stddev=0.008, seed=101)
regularizer = tf.keras.regularizers.L2(1e-4)
b_init = tf.constant_initializer()

train_data, val_data = data_path(orig_img_path='/content/drive/MyDrive/data/clear_images', hazy_img_path='/content/drive/MyDrive/data/haze')
train, val = dataloader(train_data, val_data, batch_size)

optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
net = gman_net()

train_loss_tracker = tf.keras.metrics.MeanSquaredError(name="train loss")
val_loss_tracker = tf.keras.metrics.MeanSquaredError(name="val loss")

!pip install tqdm

from tqdm import tqdm
import time

def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):

    for epoch in range(epochs):

        print("\nStart of epoch %d" % (epoch,), end=' ')
        start_time_epoch = time.time()

        # Training loop with tqdm progress bar
        for step, (train_batch_haze, train_batch_orig) in enumerate(tqdm(train, desc="Training", leave=False)):
            with tf.GradientTape() as tape:
                train_logits = net(train_batch_haze, training=True)
                loss = mean_squared_error(train_batch_orig, train_logits)

            grads = tape.gradient(loss, net.trainable_weights)
            optimizer.apply_gradients(zip(grads, net.trainable_weights))
            train_loss_tracker.update_state(train_batch_orig, train_logits)

        print('  -  Training Loss: %.4f' % (train_loss_tracker.result()), end='')

        # Validation loop with tqdm progress bar
        for step, (val_batch_haze, val_batch_orig) in enumerate(tqdm(val, desc="Validation", leave=False)):
            val_logits = net(val_batch_haze, training=False)
            val_loss_tracker.update_state(val_batch_orig, val_logits)

            if step % 32 == 0:
                display_img(net, val_batch_haze, val_batch_orig)

        print('  -  Validation Loss: %.4f' % (val_loss_tracker.result()), end='')
        print('  -  ', end=' ')
        print("Time taken: %.2fs" % (time.time() - start_time_epoch))

        net.save('trained_model')  # Save the model (variables, weights, etc.)
        train_loss_tracker.reset_states()
        val_loss_tracker.reset_states()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)

def evaluate(net, test_img_path):

    test_img = glob.glob(test_img_path + '/*.jpg')
    random.shuffle(test_img)

    for img in test_img:

        img = tf.io.read_file(img)
        img = tf.io.decode_jpeg(img, channels = 3)

        if img.shape[1] > img.shape[0]:
            img = tf.image.resize(img, size = (1080, 1920), antialias = True)
        if img.shape[1] < img.shape[0]:
            img = tf.image.resize(img, size = (1920, 1080), antialias = True)

        img = img / 255
        img = tf.expand_dims(img, axis = 0)      # transform input image from 3D to 4D

        dehaze = net(img, training = False)

        plt.figure(figsize = (80, 80))

        display_list = [img[0], dehaze[0]]       # make the first dimension zero
        title = ['Hazy Image', 'Dehazed Image']

        for i in range(2):
            plt.subplot(1, 2, i+1)
            plt.title(title[i], fontsize = 65, y = 1.045)
            plt.imshow(display_list[i])
            plt.axis('off')

        plt.show()

from google.colab import drive
drive.mount('/content/drive')

test_net = tf.keras.models.load_model('train_model', compile = False)
evaluate(test_net, '../input/hazy-test-images')

import tensorflow as tf